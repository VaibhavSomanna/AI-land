{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7c3a828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in c:\\users\\vaibhav somanna\\anaconda3\\lib\\site-packages (0.10.11)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\vaibhav somanna\\anaconda3\\lib\\site-packages (4.9.0.80)\n",
      "Requirement already satisfied: jax in c:\\users\\vaibhav somanna\\anaconda3\\lib\\site-packages (from mediapipe) (0.4.13)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in c:\\users\\vaibhav somanna\\anaconda3\\lib\\site-packages (from mediapipe) (0.4.6)\n",
      "Requirement already satisfied: numpy in c:\\users\\vaibhav somanna\\anaconda3\\lib\\site-packages (from mediapipe) (1.23.5)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\vaibhav somanna\\anaconda3\\lib\\site-packages (from mediapipe) (20.3.0)\n",
      "Requirement already satisfied: absl-py in c:\\users\\vaibhav somanna\\anaconda3\\lib\\site-packages (from mediapipe) (1.4.0)\n",
      "Requirement already satisfied: protobuf<4,>=3.11 in c:\\users\\vaibhav somanna\\anaconda3\\lib\\site-packages (from mediapipe) (3.20.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\vaibhav somanna\\anaconda3\\lib\\site-packages (from mediapipe) (23.5.26)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\vaibhav somanna\\anaconda3\\lib\\site-packages (from mediapipe) (3.3.4)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\vaibhav somanna\\anaconda3\\lib\\site-packages (from mediapipe) (4.9.0.80)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\users\\vaibhav somanna\\anaconda3\\lib\\site-packages (from sounddevice>=0.4.4->mediapipe) (1.14.5)\n",
      "Requirement already satisfied: pycparser in c:\\users\\vaibhav somanna\\anaconda3\\lib\\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.20)\n",
      "Requirement already satisfied: opt-einsum in c:\\users\\vaibhav somanna\\anaconda3\\lib\\site-packages (from jax->mediapipe) (3.3.0)\n",
      "Requirement already satisfied: ml-dtypes>=0.1.0 in c:\\users\\vaibhav somanna\\anaconda3\\lib\\site-packages (from jax->mediapipe) (0.2.0)\n",
      "Requirement already satisfied: scipy>=1.7 in c:\\users\\vaibhav somanna\\anaconda3\\lib\\site-packages (from jax->mediapipe) (1.10.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.6 in c:\\users\\vaibhav somanna\\anaconda3\\lib\\site-packages (from jax->mediapipe) (6.7.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\vaibhav somanna\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.6->jax->mediapipe) (3.4.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\vaibhav somanna\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\vaibhav somanna\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (2.8.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\vaibhav somanna\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (8.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\vaibhav somanna\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\vaibhav somanna\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (1.3.1)\n",
      "Requirement already satisfied: six in c:\\users\\vaibhav somanna\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib->mediapipe) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install mediapipe opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc7159c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyttsx3\n",
      "  Downloading pyttsx3-2.90-py3-none-any.whl (39 kB)\n",
      "Collecting pypiwin32\n",
      "  Downloading pypiwin32-223-py3-none-any.whl (1.7 kB)\n",
      "Requirement already satisfied: pywin32 in c:\\users\\vaibhav somanna\\anaconda3\\lib\\site-packages (from pyttsx3) (227)\n",
      "Requirement already satisfied: comtypes in c:\\users\\vaibhav somanna\\anaconda3\\lib\\site-packages (from pyttsx3) (1.1.9)\n",
      "Installing collected packages: pypiwin32, pyttsx3\n",
      "Successfully installed pypiwin32-223 pyttsx3-2.90\n"
     ]
    }
   ],
   "source": [
    "!pip install pyttsx3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c465e53",
   "metadata": {},
   "source": [
    "# SHOULDER PRESS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20b548cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pyttsx3\n",
    "\n",
    "# Initialize Mediapipe Pose.\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "def calculate_angle(a, b, c):\n",
    "    a = np.array(a)  # First point\n",
    "    b = np.array(b)  # Middle point\n",
    "    c = np.array(c)  # End point\n",
    "\n",
    "    radians = np.arctan2(c[1] - b[1], c[0] - b[0]) - np.arctan2(a[1] - b[1], a[0] - b[0])\n",
    "    angle = np.abs(radians * 180.0 / np.pi)\n",
    "\n",
    "    if angle > 180.0:\n",
    "        angle = 360 - angle\n",
    "\n",
    "    return angle\n",
    "\n",
    "# Start capturing video from webcam.\n",
    "cap = cv2.VideoCapture(0)  # Change index if you have multiple cameras.\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video stream.\")\n",
    "    exit()\n",
    "\n",
    "# Set the OpenCV window to be resizable.\n",
    "cv2.namedWindow('Double Arm Shoulder Press Tracking', cv2.WINDOW_NORMAL)\n",
    "\n",
    "# Maximize the window.\n",
    "cv2.setWindowProperty('Double Arm Shoulder Press Tracking', cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "\n",
    "# Initialize the text-to-speech engine.\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Initialize variables to track exercise state.\n",
    "stage = \"initial\"\n",
    "feedback_given = False  # To prevent repetitive feedback\n",
    "reps = 0\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error: Could not read frame.\")\n",
    "            break\n",
    "\n",
    "        # Convert the image to RGB.\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "\n",
    "        # Process the image and find pose.\n",
    "        results = pose.process(image)\n",
    "\n",
    "        # Convert the image back to BGR.\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "            # Get coordinates of shoulder, elbow, and wrist for both arms.\n",
    "            left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            left_elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "            left_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x, landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "\n",
    "            right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "            right_elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "            right_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "\n",
    "            # Calculate angles at the elbows for both arms.\n",
    "            left_angle = calculate_angle(left_shoulder, left_elbow, left_wrist)\n",
    "            right_angle = calculate_angle(right_shoulder, right_elbow, right_wrist)\n",
    "\n",
    "            # Visualize the angles.\n",
    "            cv2.putText(image, str(int(left_angle)),\n",
    "                        tuple(np.multiply(left_elbow, [640, 480]).astype(int)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA\n",
    "                        )\n",
    "            cv2.putText(image, str(int(right_angle)),\n",
    "                        tuple(np.multiply(right_elbow, [640, 480]).astype(int)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA\n",
    "                        )\n",
    "\n",
    "            # Check for initial L shape position\n",
    "            if stage == \"initial\" and 80 < left_angle < 100 and 80 < right_angle < 100:\n",
    "                stage = \"start\"\n",
    "                engine.say(\"Start position detected\")\n",
    "                engine.runAndWait()\n",
    "\n",
    "            # Provide corrective feedback during exercise\n",
    "            if stage == \"start\":\n",
    "                if left_angle > 160 and right_angle > 160:\n",
    "                    stage = \"up\"\n",
    "                    feedback_given = False\n",
    "\n",
    "                if left_angle < 160 or right_angle < 160:\n",
    "                    if not feedback_given:\n",
    "                        engine.say(\"Push your arms up fully.\")\n",
    "                        engine.runAndWait()\n",
    "                        feedback_given = True\n",
    "\n",
    "            if stage == \"up\" and left_angle < 90 and right_angle < 90:\n",
    "                stage = \"down\"\n",
    "                reps += 1\n",
    "                engine.say(f\"Shoulder press done correctly. Repetition count: {reps}\")\n",
    "                engine.runAndWait()\n",
    "                stage = \"initial\"  # Reset stage for the next repetition\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # Render pose landmarks on the image.\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "        # Display the output.\n",
    "        cv2.imshow('Double Arm Shoulder Press Tracking', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcad480a",
   "metadata": {},
   "source": [
    "# BICEP CURL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a97066e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pyttsx3\n",
    "\n",
    "# Initialize Mediapipe Pose.\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "def calculate_angle(a, b, c):\n",
    "    a = np.array(a)  # First point\n",
    "    b = np.array(b)  # Middle point\n",
    "    c = np.array(c)  # End point\n",
    "\n",
    "    radians = np.arctan2(c[1] - b[1], c[0] - b[0]) - np.arctan2(a[1] - b[1], a[0] - b[0])\n",
    "    angle = np.abs(radians * 180.0 / np.pi)\n",
    "\n",
    "    if angle > 180.0:\n",
    "        angle = 360 - angle\n",
    "\n",
    "    return angle\n",
    "\n",
    "# Start capturing video from webcam.\n",
    "cap = cv2.VideoCapture(0)  # Change index if you have multiple cameras.\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video stream.\")\n",
    "    exit()\n",
    "\n",
    "# Set the OpenCV window to be resizable.\n",
    "cv2.namedWindow('Bicep Curl Tracking', cv2.WINDOW_NORMAL)\n",
    "\n",
    "# Maximize the window.\n",
    "cv2.setWindowProperty('Bicep Curl Tracking', cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "\n",
    "# Initialize the text-to-speech engine.\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Initialize variables to track exercise state.\n",
    "stage = None\n",
    "feedback_given = False  # To prevent repetitive feedback\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error: Could not read frame.\")\n",
    "            break\n",
    "\n",
    "        # Convert the image to RGB.\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "\n",
    "        # Process the image and find pose.\n",
    "        results = pose.process(image)\n",
    "\n",
    "        # Convert the image back to BGR.\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "            # Get coordinates of shoulder, elbow, and wrist.\n",
    "            shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "            wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x, landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "\n",
    "            # Calculate angle at the elbow.\n",
    "            angle = calculate_angle(shoulder, elbow, wrist)\n",
    "\n",
    "            # Visualize the angle.\n",
    "            cv2.putText(image, str(int(angle)),\n",
    "                        tuple(np.multiply(elbow, [640, 480]).astype(int)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA\n",
    "                        )\n",
    "\n",
    "            # Provide corrective feedback.\n",
    "            if angle > 160 and stage == \"up\":\n",
    "                if not feedback_given:\n",
    "                    engine.say(\"Curl your arm fully.\")\n",
    "                    engine.runAndWait()\n",
    "                    feedback_given = True\n",
    "            elif angle < 160:\n",
    "                stage = \"up\"  # Transition to 'up' stage\n",
    "                feedback_given = False\n",
    "            if angle < 30 and stage == \"up\":\n",
    "                stage = \"down\"  # Transition to 'down' stage\n",
    "                engine.say(\"Bicep curl done correctly\")\n",
    "                engine.runAndWait()\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # Render pose landmarks on the image.\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "        # Display the output.\n",
    "        cv2.imshow('Bicep Curl Tracking', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95010d4",
   "metadata": {},
   "source": [
    "# ALTERNATE BICEP CURL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68c1e34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pyttsx3\n",
    "\n",
    "# Initialize Mediapipe Pose.\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Initialize the text-to-speech engine.\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "def calculate_angle(a, b, c):\n",
    "    a = np.array(a)  # First point\n",
    "    b = np.array(b)  # Middle point\n",
    "    c = np.array(c)  # End point\n",
    "\n",
    "    radians = np.arctan2(c[1] - b[1], c[0] - b[0]) - np.arctan2(a[1] - b[1], a[0] - b[0])\n",
    "    angle = np.abs(radians * 180.0 / np.pi)\n",
    "\n",
    "    if angle > 180.0:\n",
    "        angle = 360 - angle\n",
    "\n",
    "    return angle\n",
    "\n",
    "# Start capturing video from webcam.\n",
    "cap = cv2.VideoCapture(0)  # Change index if you have multiple cameras.\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video stream.\")\n",
    "    exit()\n",
    "\n",
    "# Set the OpenCV window to be resizable.\n",
    "cv2.namedWindow('Alternating Bicep Curl Tracking', cv2.WINDOW_NORMAL)\n",
    "cv2.setWindowProperty('Alternating Bicep Curl Tracking', cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "\n",
    "# Initialize variables to track exercise state.\n",
    "left_stage = \"initial\"\n",
    "right_stage = \"initial\"\n",
    "current_arm = \"left\"  # Start with the left arm\n",
    "reps = 0\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error: Could not read frame.\")\n",
    "            break\n",
    "\n",
    "        # Convert the image to RGB.\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "\n",
    "        # Process the image and find pose.\n",
    "        results = pose.process(image)\n",
    "\n",
    "        # Convert the image back to BGR.\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "            # Get coordinates of shoulder, elbow, and wrist for both arms.\n",
    "            left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            left_elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "            left_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x, landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "\n",
    "            right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "            right_elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "            right_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "\n",
    "            # Calculate angles at the elbows for both arms.\n",
    "            left_angle = calculate_angle(left_shoulder, left_elbow, left_wrist)\n",
    "            right_angle = calculate_angle(right_shoulder, right_elbow, right_wrist)\n",
    "\n",
    "            # Visualize the angles.\n",
    "            cv2.putText(image, f\"Left angle: {int(left_angle)}\", (10, 30),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            cv2.putText(image, f\"Right angle: {int(right_angle)}\", (10, 70),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "            # Enforce alternating sequence: start with the left arm\n",
    "            if current_arm == \"left\":\n",
    "                if left_stage == \"initial\" and left_angle > 160:\n",
    "                    left_stage = \"start\"\n",
    "                    engine.say(\"Start position detected for left arm. Curl your arm fully.\")\n",
    "                    engine.runAndWait()\n",
    "\n",
    "                if left_stage == \"start\" and left_angle < 60:\n",
    "                    left_stage = \"up\"\n",
    "\n",
    "                if left_stage == \"up\" and left_angle > 160:\n",
    "                    left_stage = \"initial\"\n",
    "                    reps += 1\n",
    "                    engine.say(f\"Left arm bicep curl done correctly. Repetition count: {reps}\")\n",
    "                    engine.runAndWait()\n",
    "                    current_arm = \"right\"\n",
    "\n",
    "            elif current_arm == \"right\":\n",
    "                if right_stage == \"initial\" and right_angle > 160:\n",
    "                    right_stage = \"start\"\n",
    "                    engine.say(\"Start position detected for right arm. Curl your arm fully.\")\n",
    "                    engine.runAndWait()\n",
    "\n",
    "                if right_stage == \"start\" and right_angle < 60:\n",
    "                    right_stage = \"up\"\n",
    "\n",
    "                if right_stage == \"up\" and right_angle > 160:\n",
    "                    right_stage = \"initial\"\n",
    "                    reps += 1\n",
    "                    engine.say(f\"Right arm bicep curl done correctly. Repetition count: {reps}\")\n",
    "                    engine.runAndWait()\n",
    "                    current_arm = \"left\"\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "        # Render pose landmarks on the image.\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "        # Display the output.\n",
    "        cv2.imshow('Alternating Bicep Curl Tracking', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b29691",
   "metadata": {},
   "source": [
    "# TRICEP KICKBACK EXERCISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "823966da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'landmark'\n",
      "'NoneType' object has no attribute 'landmark'\n",
      "'NoneType' object has no attribute 'landmark'\n",
      "'NoneType' object has no attribute 'landmark'\n",
      "'NoneType' object has no attribute 'landmark'\n",
      "'NoneType' object has no attribute 'landmark'\n",
      "'NoneType' object has no attribute 'landmark'\n",
      "'NoneType' object has no attribute 'landmark'\n",
      "'NoneType' object has no attribute 'landmark'\n",
      "'NoneType' object has no attribute 'landmark'\n",
      "'NoneType' object has no attribute 'landmark'\n",
      "'NoneType' object has no attribute 'landmark'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pyttsx3\n",
    "\n",
    "# Initialize Mediapipe Pose.\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Initialize the text-to-speech engine.\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "def calculate_angle(a, b, c):\n",
    "    a = np.array(a)  # First point\n",
    "    b = np.array(b)  # Middle point\n",
    "    c = np.array(c)  # End point\n",
    "\n",
    "    radians = np.arctan2(c[1] - b[1], c[0] - b[0]) - np.arctan2(a[1] - b[1], a[0] - b[0])\n",
    "    angle = np.abs(radians * 180.0 / np.pi)\n",
    "\n",
    "    if angle > 180.0:\n",
    "        angle = 360 - angle\n",
    "\n",
    "    return angle\n",
    "\n",
    "# Start capturing video from webcam.\n",
    "cap = cv2.VideoCapture(0)  # Change index if you have multiple cameras.\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video stream.\")\n",
    "    exit()\n",
    "\n",
    "# Set the OpenCV window to be resizable.\n",
    "cv2.namedWindow('Tricep Kickback Tracking', cv2.WINDOW_NORMAL)\n",
    "cv2.setWindowProperty('Tricep Kickback Tracking', cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "\n",
    "# Initialize variables to track exercise state.\n",
    "left_stage = \"initial\"\n",
    "right_stage = \"initial\"\n",
    "current_arm = \"left\"  # Start with the left arm\n",
    "reps = 0\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error: Could not read frame.\")\n",
    "            break\n",
    "\n",
    "        # Convert the image to RGB.\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "\n",
    "        # Process the image and find pose.\n",
    "        results = pose.process(image)\n",
    "\n",
    "        # Convert the image back to BGR.\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "            # Get coordinates of shoulder, elbow, and wrist for both arms.\n",
    "            left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            left_elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "            left_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x, landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "\n",
    "            right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "            right_elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "            right_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "\n",
    "            # Calculate angles at the elbows for both arms.\n",
    "            left_angle = calculate_angle(left_shoulder, left_elbow, left_wrist)\n",
    "            right_angle = calculate_angle(right_shoulder, right_elbow, right_wrist)\n",
    "\n",
    "            # Visualize the angles.\n",
    "            cv2.putText(image, f\"Left angle: {int(left_angle)}\", (10, 30),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            cv2.putText(image, f\"Right angle: {int(right_angle)}\", (10, 70),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "            # Enforce alternating sequence: start with the left arm\n",
    "            if current_arm == \"left\":\n",
    "                if left_stage == \"initial\" and left_angle < 30:\n",
    "                    left_stage = \"start\"\n",
    "                    engine.say(\"Start position detected for left arm. Extend your arm fully.\")\n",
    "                    engine.runAndWait()\n",
    "\n",
    "                if left_stage == \"start\" and left_angle > 150:\n",
    "                    left_stage = \"up\"\n",
    "\n",
    "                if left_stage == \"up\" and left_angle < 30:\n",
    "                    left_stage = \"initial\"\n",
    "                    reps += 1\n",
    "                    engine.say(f\"Left arm tricep kickback done correctly. Repetition count: {reps}\")\n",
    "                    engine.runAndWait()\n",
    "                    current_arm = \"right\"\n",
    "\n",
    "            elif current_arm == \"right\":\n",
    "                if right_stage == \"initial\" and right_angle < 30:\n",
    "                    right_stage = \"start\"\n",
    "                    engine.say(\"Start position detected for right arm. Extend your arm fully.\")\n",
    "                    engine.runAndWait()\n",
    "\n",
    "                if right_stage == \"start\" and right_angle > 150:\n",
    "                    right_stage = \"up\"\n",
    "\n",
    "                if right_stage == \"up\" and right_angle < 30:\n",
    "                    right_stage = \"initial\"\n",
    "                    reps += 1\n",
    "                    engine.say(f\"Right arm tricep kickback done correctly. Repetition count: {reps}\")\n",
    "                    engine.runAndWait()\n",
    "                    current_arm = \"left\"\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "        # Render pose landmarks on the image.\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "        # Display the output.\n",
    "        cv2.imshow('Tricep Kickback Tracking', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd68133",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
